{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fd6f8ed",
   "metadata": {},
   "source": [
    "*The first wrangling activity performed in the project was the gathering of the three separate pieces of datasets. The WeRateDogs Twitter archive was manually downloaded from the Udacity website. The tweet image predictions which contained predictions of the breed of dogs was programmatically downloaded using the python request library, and stored as as a tab separated document. The final dataset gathered was a JSON file which contained additional tweet information such as retweet and favorite count obtained from querying twitterâ€™s API using the Tweet IDs in the twitter archive. Because I was having problems querying the twitter API for this information, I manually downloaded the JSON file provided by Udacity. After the gathering phase was completed, the next wrangling activity was to access the datasets visually and programmatically. The datasets were separately loaded into the pandas dataframe and visual assessments were performed on the datasets.* \n",
    "\n",
    "*The quality and tidiness issues encountered through the visual assessment of each dataframe was documented. After the visual assessments, the datasets were separately probed further using programmatic methods. Simple codes like df.info () was used to view the general information of the dataset and df.describe() was used to gain an understanding of the summary statistics of the numerical columns in the dataframe. Going through each of the datasets and applying the correct codes for specific informations, the quality and tidiness issues encountered were documented. The quality and tidiness issues were further verified by checking each issue again and verifying them again through visual and programmatic assessments.Some of the quality and tidiness issue encountered were:*\n",
    "\n",
    "- Duplicated values or entries in the expanded url column\n",
    "- Incorrect datatype for the dog stage (doggo,floofer,pupper,puppo) columns. These are classsifications of dog stages should be   object datatypes instead of category\n",
    "\n",
    "*After having verified and properly documented each quality and tidiness issue found in each dataset, I moved to the next and the final phase of the wrangling process; Cleaning.* \n",
    "\n",
    "*To properly clean and address each quality and tidiness issue documented, a copy of each original dataset was made through programmatic(code) means. To properly clean the quality and tidiness issue found in each dataset, I used the define-code-test framework and documented it clearly. Each issue was first defined by providing a solution to address the issue, and then writing codes that can implement this solution. The code was then finally tested to see if the code has addressed the issue. Here is an example of the define ,code,test framework applied to the dataset :*\n",
    "\n",
    "- Issue : Incorrect datatype for timestamp. Float instead of datetime\n",
    "- Defining the Issue: Convert the datatype from float to timestamp\n",
    "- Code : twitter_archive_clean['timestamp'] = pd.to_datetime(twitter_archive_clean['timestamp'])\n",
    "- Test : twitter_archive_clean.info()\n",
    "\n",
    "*The final tidiness issue I addressed in this Project was to merge all the tables together on the tweet_id column using an inner join.*\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
